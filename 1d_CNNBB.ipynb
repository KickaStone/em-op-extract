{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:35:26.102130Z",
     "start_time": "2024-04-29T08:35:23.032373Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN with bound box\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNBB(nn.Module):\n",
    "    def __init__(self, number_classes):\n",
    "        super(CNNBB, self).__init__()\n",
    "        self.number_classes = number_classes\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv5 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv6 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv7 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv8 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=11, stride=1, padding='same')\n",
    "\n",
    "        self.pool1 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.AvgPool1d(kernel_size=4, stride=4)\n",
    "        self.fc1 = nn.Linear(8192, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 2048)\n",
    "        self.predictions = nn.Linear(2048, number_classes+2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 8192)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.predictions(x)\n",
    "        return x\n",
    "        # return x"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNBB(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv2): Conv1d(16, 32, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv3): Conv1d(32, 64, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv4): Conv1d(64, 128, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv5): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv6): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv7): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv8): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (pool1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  (pool2): AvgPool1d(kernel_size=(4,), stride=(4,), padding=(0,))\n",
      "  (fc1): Linear(in_features=8192, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (predictions): Linear(in_features=2048, out_features=11, bias=True)\n",
      ")\n",
      "tensor([[-0.0028,  0.0183, -0.0109,  0.0108,  0.0179,  0.0144, -0.0221, -0.0138,\n",
      "         -0.0039, -0.0076,  0.0045]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1           [-1, 16, 131072]             192\n",
      "         AvgPool1d-2            [-1, 16, 65536]               0\n",
      "            Conv1d-3            [-1, 32, 65536]           5,664\n",
      "         AvgPool1d-4            [-1, 32, 32768]               0\n",
      "            Conv1d-5            [-1, 64, 32768]          22,592\n",
      "         AvgPool1d-6            [-1, 64, 16384]               0\n",
      "            Conv1d-7           [-1, 128, 16384]          90,240\n",
      "         AvgPool1d-8            [-1, 128, 8192]               0\n",
      "            Conv1d-9            [-1, 128, 8192]         180,352\n",
      "        AvgPool1d-10            [-1, 128, 4096]               0\n",
      "           Conv1d-11            [-1, 128, 4096]         180,352\n",
      "        AvgPool1d-12            [-1, 128, 1024]               0\n",
      "           Conv1d-13            [-1, 128, 1024]         180,352\n",
      "        AvgPool1d-14             [-1, 128, 256]               0\n",
      "           Conv1d-15             [-1, 128, 256]         180,352\n",
      "        AvgPool1d-16              [-1, 128, 64]               0\n",
      "           Linear-17                 [-1, 2048]      16,779,264\n",
      "           Linear-18                 [-1, 2048]       4,196,352\n",
      "           Linear-19                   [-1, 11]          22,539\n",
      "================================================================\n",
      "Total params: 21,838,251\n",
      "Trainable params: 21,838,251\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.50\n",
      "Forward/backward pass size (MB): 114.59\n",
      "Params size (MB): 83.31\n",
      "Estimated Total Size (MB): 198.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "updated_model = CNNBB(number_classes=9).to(device)\n",
    "print(updated_model)\n",
    "\n",
    "input = torch.randn(1, 131072).to(device)\n",
    "output = updated_model(input)\n",
    "print(output)\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(updated_model, (1, 131072))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:35:29.868376Z",
     "start_time": "2024-04-29T08:35:26.104179Z"
    }
   },
   "id": "d818766ad74e191d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded.\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:35:29.959626Z",
     "start_time": "2024-04-29T08:35:29.869872Z"
    }
   },
   "id": "cbd4bfa25cdcf441",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131072,)\n",
      "{'op': 'sha1', 'datatype': 'complex64', 'left_bound': 16626.0, 'right_bound': 25172.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_data = np.load('datasets/nodemcu-random-label-train/2020-02-17_11-22-32_917765_traces.npy', allow_pickle=True)\n",
    "print(input_data[0].shape)\n",
    "input_data_meta = np.load('datasets/nodemcu-random-label-train/2020-02-17_11-22-32_917765_meta.p', allow_pickle=True)\n",
    "print(input_data_meta[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:35:29.976807Z",
     "start_time": "2024-04-29T08:35:29.961673Z"
    }
   },
   "id": "854e425c0991d531",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from batch import get_batch\n",
    "import os\n",
    "batch_size = 20\n",
    "epochs = 500\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(updated_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "datasets_root = './datasets'\n",
    "dataset_names = ['nodemcu-random-label-train']\n",
    "\n",
    "model = updated_model.to(device)\n",
    "\n",
    "def split_batch(batch):\n",
    "    inputs = np.stack(batch[:, 0], axis=0)[:, :, None]\n",
    "    targets = np.stack(batch[:, 1], axis=0)\n",
    "    labels = np.stack(batch[:, 2], axis=0)\n",
    "    inputs = np.squeeze(inputs, axis=2)\n",
    "    return inputs, targets, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:35:31.822719Z",
     "start_time": "2024-04-29T08:35:29.978318Z"
    }
   },
   "id": "55336e6f2a8fbefd",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "New Loss function\n",
    "$$L(y, \\hat{y}) = CrossEntropy(y[1,\\dots,n_0], \\hat{y}[1, \\dots, n_0]) + \\lambda_b 1_b[(w-\\hat{w})^2 + (m - \\hat{m})^2]$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a788232accb96d0c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.5891)\n"
     ]
    }
   ],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, lambda_b=100):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.lambda_b = lambda_b\n",
    "    \n",
    "    def indicator(self, y_true_cls, y_pred_cls, n_0):\n",
    "        correct = y_true_cls == y_pred_cls\n",
    "        not_noise = y_true_cls != n_0 - 1\n",
    "        return (correct & not_noise).float()\n",
    "        \n",
    "    # input tensor shape : [batch_size, n_b + 2]\n",
    "    def forward(self, y_pred, y_true):\n",
    "        n_0 = y_true.size(1) - 2\n",
    "        y_hat_cls = y_pred[:, :n_0]\n",
    "        y_true_cls = y_true[:, :n_0]\n",
    "        y_hat_w = y_pred[:, -2]\n",
    "        y_hat_m = y_pred[:, -1]\n",
    "        y_true_w = y_true[:, -2]\n",
    "        y_true_m = y_true[:, -1]\n",
    "        \n",
    "        y_true_cls = y_true_cls.argmax(dim=1)\n",
    "        y_pred_cls = y_hat_cls.argmax(dim=1)\n",
    "        \n",
    "        ind = self.indicator(y_true_cls, y_pred_cls, n_0)\n",
    "        loss_cls = F.cross_entropy(y_hat_cls, y_true_cls)\n",
    "        return loss_cls + (self.lambda_b*ind*((y_true_w-y_hat_w)**2 + (y_true_m - y_hat_m)**2)).mean()\n",
    "        \n",
    "# y_pred = torch.randn(10, 11)\n",
    "# y_true = torch.randn(10, 11)\n",
    "# criterion = CustomLoss()\n",
    "# print(criterion(y_pred, y_true))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:35:31.838243Z",
     "start_time": "2024-04-29T08:35:31.824251Z"
    }
   },
   "id": "f1d45f09009b0280",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "pretrained_dict= torch.load('./models/best_cnn-epoch-10.pt')\n",
    "updated_model.load_state_dict(pretrained_dict, strict=False)\n",
    "print(\"Pre-trained model loaded.\")\n",
    "\n",
    "batch_c = []  # Batch container\n",
    "for dataset_name in dataset_names:\n",
    "    dataset_path = os.path.join(datasets_root, dataset_name)\n",
    "    dataset_files = list(os.listdir(dataset_path))\n",
    "    for epoch in range(epochs):\n",
    "        cnt = 0\n",
    "        for i, dataset_file in enumerate(dataset_files):\n",
    "            if '_traces.npy' in dataset_file:\n",
    "                for batch in get_batch(dataset_path, dataset_file, batch_c, batch_size=batch_size, with_bound=True):\n",
    "                    cnt += 1\n",
    "                    input, target, label = split_batch(batch)\n",
    "                    xs = torch.tensor(input).float().to(device)\n",
    "                    ys = torch.tensor(label).float().to(device)\n",
    "                    # print(ys, ys.shape)\n",
    "                    # print(label, label.shape)\n",
    "                    y_pred = model(xs)             \n",
    "                    loss = criterion(y_pred, ys)\n",
    "                    print(f'Epoch {epoch}, Batch {cnt}, Loss: {loss.item()}')\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "                    optimizer.step()\n",
    "        # Save model\n",
    "        if epoch % 50 == 0:\n",
    "            torch.save(model.state_dict(), f'./models/CNNBB-epoch-{epoch}.pt')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be19ca6dc3e2d61d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this experiment, we obtain an accuracy of 74.90%, and a precision and recall of respectively 77.84% and 77.87%. The mean absolute error of the bounding box predictions with respect to the ground truth for 239 traces containing an operation is 429.81 Î¼s (24,069 samples) per trace. Although the classification accuracy is lower compared to the experiments without bounding boxes, we still believe this is a good result given the limited set of 256 labeled training examples."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f510489fd4a43058"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aes_tiny left_bound: 16376.857421875 right_bound: 53435.001953125\n",
      "aes_tiny left_bound: 7376.0 right_bound: 57002.0\n",
      "\n",
      "aes_tiny left_bound: 16382.775390625 right_bound: 53642.099609375\n",
      "aes left_bound: 20330.0 right_bound: 23728.0\n",
      "\n",
      "aes_tiny left_bound: 16253.05859375 right_bound: 52893.23046875\n",
      "aes_openssl left_bound: 10211.0 right_bound: 17239.0\n",
      "\n",
      "aes_tiny left_bound: 15459.826171875 right_bound: 53757.947265625\n",
      "sha1 left_bound: 6849.0 right_bound: 15623.0\n",
      "\n",
      "aes_tiny left_bound: 16161.875 right_bound: 53948.234375\n",
      "sha1prf left_bound: 4430.0 right_bound: 56778.0\n",
      "\n",
      "aes_tiny left_bound: 15230.853515625 right_bound: 54049.271484375\n",
      "sha1 left_bound: 6204.0 right_bound: 14963.0\n",
      "\n",
      "aes_tiny left_bound: 15313.578125 right_bound: 53687.828125\n",
      "aes left_bound: 2522.0 right_bound: 5591.0\n",
      "\n",
      "aes_tiny left_bound: 15911.716796875 right_bound: 52979.400390625\n",
      "aes_openssl left_bound: 14735 right_bound: 22558.0\n",
      "\n",
      "aes_tiny left_bound: 16094.859375 right_bound: 53110.6171875\n",
      "hmacsha1 left_bound: 3178.0 right_bound: 16257.0\n",
      "\n",
      "aes_tiny left_bound: 16931.970703125 right_bound: 52959.318359375\n",
      "sha1 left_bound: 2378.0 right_bound: 11032.0\n",
      "\n",
      "aes_tiny left_bound: 16642.365234375 right_bound: 53492.970703125\n",
      "sha1prf left_bound: 6744.0 right_bound: 58903.0\n",
      "\n",
      "aes_tiny left_bound: 17108.466796875 right_bound: 53139.166015625\n",
      "hmacsha1 left_bound: 8291.0 right_bound: 21395.0\n",
      "\n",
      "aes_tiny left_bound: 16790.265625 right_bound: 53449.03125\n",
      "aes_tiny left_bound: 4057.0 right_bound: 54492.0\n",
      "\n",
      "aes_tiny left_bound: 15360.55078125 right_bound: 54522.64453125\n",
      "sha1prf left_bound: 3843.0 right_bound: 56065.0\n",
      "\n",
      "aes_tiny left_bound: 15317.126953125 right_bound: 54524.951171875\n",
      "sha1prf left_bound: 8055.0 right_bound: 60390.0\n",
      "\n",
      "aes_tiny left_bound: 15283.025390625 right_bound: 54015.076171875\n",
      "hmacsha1 left_bound: 5032.0 right_bound: 18125.0\n"
     ]
    }
   ],
   "source": [
    "from common import plot_meta, int_to_op, pad_to_length\n",
    "\n",
    "test_trace = 'datasets/nodemcu-random-label-test/2020-02-17_11-15-41_686854_traces.npy'\n",
    "test_meta = 'datasets/nodemcu-random-label-test/2020-02-17_11-15-41_686854_meta.p'\n",
    "traces = np.load(test_trace, allow_pickle=True)\n",
    "metas = np.load(test_meta, allow_pickle=True)\n",
    "\n",
    "\n",
    "state_dict = torch.load('models/CNNBB-epoch-100.pt')\n",
    "updated_model.load_state_dict(state_dict)\n",
    "\n",
    "trace_index = 2\n",
    "for trace_index in range(16):\n",
    "\n",
    "    updated_model.to(device)\n",
    "    trace = pad_to_length(traces[trace_index], 131072)\n",
    "    meta = metas[trace_index]\n",
    "    \n",
    "    x = trace.reshape(1, -1)\n",
    "    y = updated_model(torch.tensor(x).float().to(device))\n",
    "    y = y.cpu().detach().numpy().flatten()\n",
    "    \n",
    "    # print('y = ', y)\n",
    "    op = int_to_op[np.argmax(y[:-2])]\n",
    "    mid = y[-2]* 131072\n",
    "    length = y[-1]*131072\n",
    "    left_bound = mid - length/2\n",
    "    right_bound = left_bound + length\n",
    "    print(op, 'left_bound:', left_bound, 'right_bound:', right_bound)\n",
    "    print(meta['op'], 'left_bound:', meta['left_bound'], 'right_bound:', meta['right_bound'])\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:46:10.372380Z",
     "start_time": "2024-04-29T08:46:10.178109Z"
    }
   },
   "id": "e2270018257aee4e",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
