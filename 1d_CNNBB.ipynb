{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:35:26.102130Z",
     "start_time": "2024-04-29T08:35:23.032373Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN with bound box\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNBB(nn.Module):\n",
    "    def __init__(self, number_classes):\n",
    "        super(CNNBB, self).__init__()\n",
    "        self.number_classes = number_classes\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv5 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv6 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv7 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=11, stride=1, padding='same')\n",
    "        self.conv8 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=11, stride=1, padding='same')\n",
    "\n",
    "        self.pool1 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.AvgPool1d(kernel_size=4, stride=4)\n",
    "        self.fc1 = nn.Linear(8192, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 2048)\n",
    "        self.predictions = nn.Linear(2048, number_classes+2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 8192)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.predictions(x)\n",
    "        return x\n",
    "        # return x"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNBB(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv2): Conv1d(16, 32, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv3): Conv1d(32, 64, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv4): Conv1d(64, 128, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv5): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv6): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv7): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (conv8): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=same)\n",
      "  (pool1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  (pool2): AvgPool1d(kernel_size=(4,), stride=(4,), padding=(0,))\n",
      "  (fc1): Linear(in_features=8192, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (predictions): Linear(in_features=2048, out_features=11, bias=True)\n",
      ")\n",
      "tensor([[-0.0028,  0.0183, -0.0109,  0.0108,  0.0179,  0.0144, -0.0221, -0.0138,\n",
      "         -0.0039, -0.0076,  0.0045]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1           [-1, 16, 131072]             192\n",
      "         AvgPool1d-2            [-1, 16, 65536]               0\n",
      "            Conv1d-3            [-1, 32, 65536]           5,664\n",
      "         AvgPool1d-4            [-1, 32, 32768]               0\n",
      "            Conv1d-5            [-1, 64, 32768]          22,592\n",
      "         AvgPool1d-6            [-1, 64, 16384]               0\n",
      "            Conv1d-7           [-1, 128, 16384]          90,240\n",
      "         AvgPool1d-8            [-1, 128, 8192]               0\n",
      "            Conv1d-9            [-1, 128, 8192]         180,352\n",
      "        AvgPool1d-10            [-1, 128, 4096]               0\n",
      "           Conv1d-11            [-1, 128, 4096]         180,352\n",
      "        AvgPool1d-12            [-1, 128, 1024]               0\n",
      "           Conv1d-13            [-1, 128, 1024]         180,352\n",
      "        AvgPool1d-14             [-1, 128, 256]               0\n",
      "           Conv1d-15             [-1, 128, 256]         180,352\n",
      "        AvgPool1d-16              [-1, 128, 64]               0\n",
      "           Linear-17                 [-1, 2048]      16,779,264\n",
      "           Linear-18                 [-1, 2048]       4,196,352\n",
      "           Linear-19                   [-1, 11]          22,539\n",
      "================================================================\n",
      "Total params: 21,838,251\n",
      "Trainable params: 21,838,251\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.50\n",
      "Forward/backward pass size (MB): 114.59\n",
      "Params size (MB): 83.31\n",
      "Estimated Total Size (MB): 198.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "updated_model = CNNBB(number_classes=9).to(device)\n",
    "print(updated_model)\n",
    "\n",
    "input = torch.randn(1, 131072).to(device)\n",
    "output = updated_model(input)\n",
    "print(output)\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(updated_model, (1, 131072))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:35:29.868376Z",
     "start_time": "2024-04-29T08:35:26.104179Z"
    }
   },
   "id": "d818766ad74e191d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded.\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:35:29.959626Z",
     "start_time": "2024-04-29T08:35:29.869872Z"
    }
   },
   "id": "cbd4bfa25cdcf441",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131072,)\n",
      "{'op': 'sha1', 'datatype': 'complex64', 'left_bound': 16626.0, 'right_bound': 25172.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_data = np.load('datasets/nodemcu-random-label-train/2020-02-17_11-22-32_917765_traces.npy', allow_pickle=True)\n",
    "print(input_data[0].shape)\n",
    "input_data_meta = np.load('datasets/nodemcu-random-label-train/2020-02-17_11-22-32_917765_meta.p', allow_pickle=True)\n",
    "print(input_data_meta[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:35:29.976807Z",
     "start_time": "2024-04-29T08:35:29.961673Z"
    }
   },
   "id": "854e425c0991d531",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from batch import get_batch\n",
    "import os\n",
    "batch_size = 20\n",
    "epochs = 500\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(updated_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "datasets_root = './datasets'\n",
    "dataset_names = ['nodemcu-random-label-train']\n",
    "\n",
    "model = updated_model.to(device)\n",
    "\n",
    "def split_batch(batch):\n",
    "    inputs = np.stack(batch[:, 0], axis=0)[:, :, None]\n",
    "    targets = np.stack(batch[:, 1], axis=0)\n",
    "    labels = np.stack(batch[:, 2], axis=0)\n",
    "    inputs = np.squeeze(inputs, axis=2)\n",
    "    return inputs, targets, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:35:31.822719Z",
     "start_time": "2024-04-29T08:35:29.978318Z"
    }
   },
   "id": "55336e6f2a8fbefd",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "New Loss function\n",
    "$$L(y, \\hat{y}) = CrossEntropy(y[1,\\dots,n_0], \\hat{y}[1, \\dots, n_0]) + \\lambda_b 1_b[(w-\\hat{w})^2 + (m - \\hat{m})^2]$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a788232accb96d0c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.5891)\n"
     ]
    }
   ],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, lambda_b=100):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.lambda_b = lambda_b\n",
    "    \n",
    "    def indicator(self, y_true_cls, y_pred_cls, n_0):\n",
    "        correct = y_true_cls == y_pred_cls\n",
    "        not_noise = y_true_cls != n_0 - 1\n",
    "        return (correct & not_noise).float()\n",
    "        \n",
    "    # input tensor shape : [batch_size, n_b + 2]\n",
    "    def forward(self, y_pred, y_true):\n",
    "        n_0 = y_true.size(1) - 2\n",
    "        y_hat_cls = y_pred[:, :n_0]\n",
    "        y_true_cls = y_true[:, :n_0]\n",
    "        y_hat_w = y_pred[:, -2]\n",
    "        y_hat_m = y_pred[:, -1]\n",
    "        y_true_w = y_true[:, -2]\n",
    "        y_true_m = y_true[:, -1]\n",
    "        \n",
    "        y_true_cls = y_true_cls.argmax(dim=1)\n",
    "        y_pred_cls = y_hat_cls.argmax(dim=1)\n",
    "        \n",
    "        ind = self.indicator(y_true_cls, y_pred_cls, n_0)\n",
    "        loss_cls = F.cross_entropy(y_hat_cls, y_true_cls)\n",
    "        return loss_cls + (self.lambda_b*ind*((y_true_w-y_hat_w)**2 + (y_true_m - y_hat_m)**2)).mean()\n",
    "        \n",
    "# y_pred = torch.randn(10, 11)\n",
    "# y_true = torch.randn(10, 11)\n",
    "# criterion = CustomLoss()\n",
    "# print(criterion(y_pred, y_true))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:35:31.838243Z",
     "start_time": "2024-04-29T08:35:31.824251Z"
    }
   },
   "id": "f1d45f09009b0280",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "pretrained_dict= torch.load('./models/best_cnn-epoch-10.pt')\n",
    "updated_model.load_state_dict(pretrained_dict, strict=False)\n",
    "print(\"Pre-trained model loaded.\")\n",
    "\n",
    "batch_c = []  # Batch container\n",
    "for dataset_name in dataset_names:\n",
    "    dataset_path = os.path.join(datasets_root, dataset_name)\n",
    "    dataset_files = list(os.listdir(dataset_path))\n",
    "    for epoch in range(epochs):\n",
    "        cnt = 0\n",
    "        for i, dataset_file in enumerate(dataset_files):\n",
    "            if '_traces.npy' in dataset_file:\n",
    "                for batch in get_batch(dataset_path, dataset_file, batch_c, batch_size=batch_size, with_bound=True):\n",
    "                    cnt += 1\n",
    "                    input, target, label = split_batch(batch)\n",
    "                    xs = torch.tensor(input).float().to(device)\n",
    "                    ys = torch.tensor(label).float().to(device)\n",
    "                    # print(ys, ys.shape)\n",
    "                    # print(label, label.shape)\n",
    "                    y_pred = model(xs)             \n",
    "                    loss = criterion(y_pred, ys)\n",
    "                    print(f'Epoch {epoch}, Batch {cnt}, Loss: {loss.item()}')\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "                    optimizer.step()\n",
    "        # Save model\n",
    "        if epoch % 50 == 0:\n",
    "            torch.save(model.state_dict(), f'./models/CNNBB-epoch-{epoch}.pt')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be19ca6dc3e2d61d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this experiment, we obtain an accuracy of 74.90%, and a precision and recall of respectively 77.84% and 77.87%. The mean absolute error of the bounding box predictions with respect to the ground truth for 239 traces containing an operation is 429.81 μs (24,069 samples) per trace. Although the classification accuracy is lower compared to the experiments without bounding boxes, we still believe this is a good result given the limited set of 256 labeled training examples."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f510489fd4a43058"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aes_tiny left_bound: 16376.857421875 right_bound: 53435.001953125\n",
      "aes_tiny left_bound: 7376.0 right_bound: 57002.0\n",
      "\n",
      "aes_tiny left_bound: 16382.775390625 right_bound: 53642.099609375\n",
      "aes left_bound: 20330.0 right_bound: 23728.0\n",
      "\n",
      "aes_tiny left_bound: 16253.05859375 right_bound: 52893.23046875\n",
      "aes_openssl left_bound: 10211.0 right_bound: 17239.0\n",
      "\n",
      "aes_tiny left_bound: 15459.826171875 right_bound: 53757.947265625\n",
      "sha1 left_bound: 6849.0 right_bound: 15623.0\n",
      "\n",
      "aes_tiny left_bound: 16161.875 right_bound: 53948.234375\n",
      "sha1prf left_bound: 4430.0 right_bound: 56778.0\n",
      "\n",
      "aes_tiny left_bound: 15230.853515625 right_bound: 54049.271484375\n",
      "sha1 left_bound: 6204.0 right_bound: 14963.0\n",
      "\n",
      "aes_tiny left_bound: 15313.578125 right_bound: 53687.828125\n",
      "aes left_bound: 2522.0 right_bound: 5591.0\n",
      "\n",
      "aes_tiny left_bound: 15911.716796875 right_bound: 52979.400390625\n",
      "aes_openssl left_bound: 14735 right_bound: 22558.0\n",
      "\n",
      "aes_tiny left_bound: 16094.859375 right_bound: 53110.6171875\n",
      "hmacsha1 left_bound: 3178.0 right_bound: 16257.0\n",
      "\n",
      "aes_tiny left_bound: 16931.970703125 right_bound: 52959.318359375\n",
      "sha1 left_bound: 2378.0 right_bound: 11032.0\n",
      "\n",
      "aes_tiny left_bound: 16642.365234375 right_bound: 53492.970703125\n",
      "sha1prf left_bound: 6744.0 right_bound: 58903.0\n",
      "\n",
      "aes_tiny left_bound: 17108.466796875 right_bound: 53139.166015625\n",
      "hmacsha1 left_bound: 8291.0 right_bound: 21395.0\n",
      "\n",
      "aes_tiny left_bound: 16790.265625 right_bound: 53449.03125\n",
      "aes_tiny left_bound: 4057.0 right_bound: 54492.0\n",
      "\n",
      "aes_tiny left_bound: 15360.55078125 right_bound: 54522.64453125\n",
      "sha1prf left_bound: 3843.0 right_bound: 56065.0\n",
      "\n",
      "aes_tiny left_bound: 15317.126953125 right_bound: 54524.951171875\n",
      "sha1prf left_bound: 8055.0 right_bound: 60390.0\n",
      "\n",
      "aes_tiny left_bound: 15283.025390625 right_bound: 54015.076171875\n",
      "hmacsha1 left_bound: 5032.0 right_bound: 18125.0\n"
     ]
    }
   ],
   "source": [
    "from common import plot_meta, int_to_op, pad_to_length\n",
    "\n",
    "test_trace = 'datasets/nodemcu-random-label-test/2020-02-17_11-15-41_686854_traces.npy'\n",
    "test_meta = 'datasets/nodemcu-random-label-test/2020-02-17_11-15-41_686854_meta.p'\n",
    "traces = np.load(test_trace, allow_pickle=True)\n",
    "metas = np.load(test_meta, allow_pickle=True)\n",
    "\n",
    "\n",
    "state_dict = torch.load('models/CNNBB-epoch-100.pt')\n",
    "updated_model.load_state_dict(state_dict)\n",
    "\n",
    "trace_index = 2\n",
    "for trace_index in range(16):\n",
    "\n",
    "    updated_model.to(device)\n",
    "    trace = pad_to_length(traces[trace_index], 131072)\n",
    "    meta = metas[trace_index]\n",
    "    \n",
    "    x = trace.reshape(1, -1)\n",
    "    y = updated_model(torch.tensor(x).float().to(device))\n",
    "    y = y.cpu().detach().numpy().flatten()\n",
    "    \n",
    "    # print('y = ', y)\n",
    "    op = int_to_op[np.argmax(y[:-2])]\n",
    "    mid = y[-2]* 131072\n",
    "    length = y[-1]*131072\n",
    "    left_bound = mid - length/2\n",
    "    right_bound = left_bound + length\n",
    "    print(op, 'left_bound:', left_bound, 'right_bound:', right_bound)\n",
    "    print(meta['op'], 'left_bound:', meta['left_bound'], 'right_bound:', meta['right_bound'])\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:46:10.372380Z",
     "start_time": "2024-04-29T08:46:10.178109Z"
    }
   },
   "id": "e2270018257aee4e",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
